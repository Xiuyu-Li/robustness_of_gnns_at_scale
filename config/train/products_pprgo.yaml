seml:
  name: rgnn_products_train
  executable: experiments/experiment_train.py
  project_root_dir: ../..
  output_dir: config/train/output


slurm:
  experiments_per_job: 1
  sbatch_options:
    gres: gpu:1       # num GPUs
    mem: 48G          # memory
    cpus-per-task: 4  # num cores
    time: 1-00:00     # max time, D-HH:MM
    qos: interactive

fixed:
  data_dir: data/
  dataset: ogbn-products
  perturbed: False
  ptb_rate: 0.0
  binary_attr: False
  train_params:
    log_dir: runs/products
    max_epochs: 30
    patience: 300
  artifact_dir: cache
  model_storage_type: pretrained
  device: 0
  data_device: cpu

grid:
  seed: 
    type: choice
    options:
      - 0
      # - 1
      # - 5
  make_undirected: 
    type: choice
    options:
      - True
      # - False


# pprgo:
#   fixed:
#     model_params:
#       label: Vanilla PPRGo
#       model: PPRGo
#       topk: 128
#       eps: 1e-5
#       alpha: 0.1
#       ppr_normalization: row
#       dropout: 0.0
#       n_filters: 512
#       n_layers: 4
#       batch_norm: True
#     train_params:
#       lr: 1e-2
#       weight_decay: 0
#       batch_size: 2048
#       batch_mult_val: 1
#       forward_batch_size: 512
#       use_annealing_scheduler: False


soft_median_5_0_pprgo:
  fixed:
    model_params:
      label: Soft Median PPRGo (T=5.0)
      model: RobustPPRGo
      topk: 128
      eps: 1e-5
      alpha: 0.1
      ppr_normalization: row
      batch_norm: True
      dropout: 0.0
      n_filters: 512
      n_layers: 4
      mean: soft_median
      mean_kwargs: 
        temperature: 5.0
    train_params:
      lr: 1e-2
      weight_decay: 5e-5
      batch_size: 2048
      batch_mult_val: 1
      forward_batch_size: 512


# soft_median_1_0_pprgo:
#   fixed:
#     model_params:
#       label: Soft Median PPRGo (T=1.0)
#       model: RobustPPRGo
#       topk: 128
#       eps: 1e-5
#       alpha: 0.1
#       ppr_normalization: row
#       batch_norm: True
#       dropout: 0.0
#       n_filters: 512
#       n_layers: 4
#       mean: soft_median
#       mean_kwargs: 
#         temperature: 1.0
#     train_params:
#       lr: 1e-2
#       weight_decay: 5e-5
#       batch_size: 2048
#       batch_mult_val: 1
#       forward_batch_size: 512
